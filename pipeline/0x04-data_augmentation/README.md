    You are currently observing these locations: BOG, MDE, CLO, BAQ, UIO        Change * Check/Uncheck all locations
*             [BOG] Holberton Bogotá, Colombia          
*             [MDE] Holberton Medellín, Colombia          
*             [CLO] Holberton Cali, Colombia          
*             [BAQ] Holberton Barranquilla, Colombia          
*             [UIO] Holberton Quito, Ecuador          
            You are currently connected as Staff            Switch to:            [Student](https://intranet.hbtn.io/users/switch_viewing_as_permission_group?group=student) 
 |         
# 0x04. Data Augmentation
## Details
 By: Alexa Orrico, Software Engineer at Holberton School Weight: 1 Manual review behavior:Any student### Admin corner
[Cohort adjustments](https://intranet.hbtn.io/projects/852#) 
[Preview manual QA review sheet](https://intranet.hbtn.io/corrections/preview_correct?project_id=852) 
×#### Cohort adjustment for Project - 852
[New](https://intranet.hbtn.io/batch_projects/new?project_id=852) 
 /.modal-content  /.modal-dialog  /.modal * [Metadata](https://intranet.hbtn.io/projects/852#admin-corner-metadata) 

* [Started by cohorts](https://intranet.hbtn.io/projects/852#admin-corner-batches) 

* [Peer learning days](https://intranet.hbtn.io/projects/852#admin-corner-plds) 

* [Resource links](https://intranet.hbtn.io/projects/852#admin-corner-resources) 

* [Reminders](https://intranet.hbtn.io/projects/852#admin-corner-reminders) 

* [Dependencies](https://intranet.hbtn.io/projects/852#admin-corner-dependencies) 

*       Main code language:     
*       Project will be corrected at 00:00 (school location time)    
*     Track:   
*     Block: [The Pipeline](https://intranet.hbtn.io/blocks/65) 

* Online
*     Must be corrected: true  
*     Tasks mode:   
*     Task level review type: Test review  
*       Weight: 1    
*     Position: 5  
*     Days offset: 3  
*     Duration: 2 days  
*     Work hours: 16 hours  
*     Project to be done in teams of 1 people  
*     Team distribution algo:   
*     Excluded from check contributors: false    

[BAQ-0621](https://intranet.hbtn.io/batches/111) 
        ([from 2022-12-12 to 2022-12-14](https://intranet.hbtn.io/batch_planning_items/37086) 
)      [BOG-0621](https://intranet.hbtn.io/batches/113) 
        ([from 2022-12-12 to 2022-12-14](https://intranet.hbtn.io/batch_planning_items/37094) 
)      [BOG-0121](https://intranet.hbtn.io/batches/78) 
        ([from 2022-08-08 to 2022-08-10](https://intranet.hbtn.io/batch_planning_items/31234) 
)      [MDE-0121](https://intranet.hbtn.io/batches/80) 
        ([from 2022-08-08 to 2022-08-10](https://intranet.hbtn.io/batch_planning_items/31246) 
)      [BAQ-0121](https://intranet.hbtn.io/batches/77) 
        ([from 2022-08-08 to 2022-08-10](https://intranet.hbtn.io/batch_planning_items/31253) 
)      [BOG-0920](https://intranet.hbtn.io/batches/58) 
        ([from 2022-03-21 to 2022-03-23](https://intranet.hbtn.io/batch_planning_items/23336) 
)      [MDE-0920](https://intranet.hbtn.io/batches/59) 
        ([from 2022-03-21 to 2022-03-23](https://intranet.hbtn.io/batch_planning_items/23346) 
)      [CLO-0920](https://intranet.hbtn.io/batches/55) 
        ([from 2022-03-21 to 2022-03-23](https://intranet.hbtn.io/batch_planning_items/23356) 
)      [BOG-0620](https://intranet.hbtn.io/batches/46) 
        ([from 2021-12-13 to 2021-12-15](https://intranet.hbtn.io/batch_planning_items/18808) 
)      [MDE-0620](https://intranet.hbtn.io/batches/45) 
        ([from 2021-12-13 to 2021-12-15](https://intranet.hbtn.io/batch_planning_items/18827) 
)      [CLO-0620](https://intranet.hbtn.io/batches/44) 
        ([from 2021-12-13 to 2021-12-15](https://intranet.hbtn.io/batch_planning_items/18845) 
)      [MDE-0121-C11](https://intranet.hbtn.io/batches/100) 
        ([from 2021-09-20 to 2021-09-22](https://intranet.hbtn.io/batch_planning_items/15517) 
)      [CLO-0121-C11](https://intranet.hbtn.io/batches/99) 
        ([from 2021-09-20 to 2021-09-22](https://intranet.hbtn.io/batch_planning_items/15535) 
)      [BOG-0120](https://intranet.hbtn.io/batches/33) 
        ([from 2021-08-09 to 2021-08-11](https://intranet.hbtn.io/batch_planning_items/14114) 
)      [MDE-0120](https://intranet.hbtn.io/batches/35) 
        ([from 2021-08-09 to 2021-08-11](https://intranet.hbtn.io/batch_planning_items/14133) 
)      [CLO-0120](https://intranet.hbtn.io/batches/34) 
        ([from 2021-08-09 to 2021-08-11](https://intranet.hbtn.io/batch_planning_items/14149) 
)      [BAQ-0120](https://intranet.hbtn.io/batches/41) 
        ([from 2021-08-09 to 2021-08-11](https://intranet.hbtn.io/batch_planning_items/14182) 
)      [MDE-0919](https://intranet.hbtn.io/batches/27) 
        ([from 2021-03-23 to 2021-03-27](https://intranet.hbtn.io/batch_planning_items/10242) 
)      [CLO-0919](https://intranet.hbtn.io/batches/31) 
        ([from 2021-03-23 to 2021-03-27](https://intranet.hbtn.io/batch_planning_items/10247) 
)      [BOG-0919](https://intranet.hbtn.io/batches/26) 
        ([from 2021-03-23 to 2021-03-27](https://intranet.hbtn.io/batch_planning_items/10237) 
)      [BOG-0619](https://intranet.hbtn.io/batches/23) 
        ([from 2020-11-10 to 2020-11-17](https://intranet.hbtn.io/batch_planning_items/7450) 
)      [MDE-0619](https://intranet.hbtn.io/batches/22) 
        ([from 2020-11-10 to 2020-11-17](https://intranet.hbtn.io/batch_planning_items/7451) 
)      [BOG-0119](https://intranet.hbtn.io/batches/21) 
        ([from 2020-10-07 to 2020-10-09](https://intranet.hbtn.io/batch_planning_items/6918) 
)      [UIO-0621](https://intranet.hbtn.io/batches/129) 
        ([from 2022-12-16 to 2022-12-17](https://intranet.hbtn.io/batch_peer_learning_day_items/8385) 
)      [CLO-0621](https://intranet.hbtn.io/batches/109) 
        ([from 2022-12-16 to 2022-12-17](https://intranet.hbtn.io/batch_peer_learning_day_items/8377) 
)      [MDE-0621](https://intranet.hbtn.io/batches/116) 
        ([from 2022-12-16 to 2022-12-17](https://intranet.hbtn.io/batch_peer_learning_day_items/8372) 
)      [BOG-0621](https://intranet.hbtn.io/batches/113) 
        ([from 2022-12-16 to 2022-12-17](https://intranet.hbtn.io/batch_peer_learning_day_items/8371) 
)      [BAQ-0621](https://intranet.hbtn.io/batches/111) 
        ([from 2022-12-16 to 2022-12-17](https://intranet.hbtn.io/batch_peer_learning_day_items/8368) 
)      [BAQ-0121](https://intranet.hbtn.io/batches/77) 
        ([from 2022-08-12 to 2022-08-13](https://intranet.hbtn.io/batch_peer_learning_day_items/7492) 
)      [CLO-0121](https://intranet.hbtn.io/batches/79) 
        ([from 2022-08-12 to 2022-08-13](https://intranet.hbtn.io/batch_peer_learning_day_items/7490) 
)      [MDE-0121](https://intranet.hbtn.io/batches/80) 
        ([from 2022-08-12 to 2022-08-13](https://intranet.hbtn.io/batch_peer_learning_day_items/7486) 
)      [BOG-0121](https://intranet.hbtn.io/batches/78) 
        ([from 2022-08-12 to 2022-08-13](https://intranet.hbtn.io/batch_peer_learning_day_items/7482) 
)      [BAQ-0920](https://intranet.hbtn.io/batches/57) 
        ([from 2022-03-25 to 2022-03-26](https://intranet.hbtn.io/batch_peer_learning_day_items/6227) 
)      [CLO-0920](https://intranet.hbtn.io/batches/55) 
        ([from 2022-03-25 to 2022-03-26](https://intranet.hbtn.io/batch_peer_learning_day_items/6216) 
)      [MDE-0920](https://intranet.hbtn.io/batches/59) 
        ([from 2022-03-25 to 2022-03-26](https://intranet.hbtn.io/batch_peer_learning_day_items/6211) 
)      [BOG-0920](https://intranet.hbtn.io/batches/58) 
        ([from 2022-03-25 to 2022-03-26](https://intranet.hbtn.io/batch_peer_learning_day_items/6206) 
)      [BAQ-0620](https://intranet.hbtn.io/batches/47) 
        ([from 2021-12-17 to 2021-12-18](https://intranet.hbtn.io/batch_peer_learning_day_items/5235) 
)      [CLO-0620](https://intranet.hbtn.io/batches/44) 
        ([from 2021-12-17 to 2021-12-18](https://intranet.hbtn.io/batch_peer_learning_day_items/5229) 
)      [MDE-0620](https://intranet.hbtn.io/batches/45) 
        ([from 2021-12-17 to 2021-12-18](https://intranet.hbtn.io/batch_peer_learning_day_items/5227) 
)      [BOG-0620](https://intranet.hbtn.io/batches/46) 
        ([from 2021-12-17 to 2021-12-18](https://intranet.hbtn.io/batch_peer_learning_day_items/5225) 
)      [CLO-0121-C11](https://intranet.hbtn.io/batches/99) 
        ([from 2021-09-24 to 2021-09-25](https://intranet.hbtn.io/batch_peer_learning_day_items/4477) 
)      [MDE-0121-C11](https://intranet.hbtn.io/batches/100) 
        ([from 2021-09-24 to 2021-09-25](https://intranet.hbtn.io/batch_peer_learning_day_items/4474) 
)      [BOG-0121-C11](https://intranet.hbtn.io/batches/97) 
        ([from 2021-09-24 to 2021-09-25](https://intranet.hbtn.io/batch_peer_learning_day_items/4470) 
)      [BAQ-0120](https://intranet.hbtn.io/batches/41) 
        ([from 2021-08-13 to 2021-08-14](https://intranet.hbtn.io/batch_peer_learning_day_items/4112) 
)      [CLO-0120](https://intranet.hbtn.io/batches/34) 
        ([from 2021-08-13 to 2021-08-14](https://intranet.hbtn.io/batch_peer_learning_day_items/4106) 
)      [MDE-0120](https://intranet.hbtn.io/batches/35) 
        ([from 2021-08-13 to 2021-08-14](https://intranet.hbtn.io/batch_peer_learning_day_items/4103) 
)      [BOG-0120](https://intranet.hbtn.io/batches/33) 
        ([from 2021-08-13 to 2021-08-14](https://intranet.hbtn.io/batch_peer_learning_day_items/4100) 
)      [CLO-0919](https://intranet.hbtn.io/batches/31) 
        ([from 2021-04-15 to 2021-04-16](https://intranet.hbtn.io/batch_peer_learning_day_items/3106) 
)      [MDE-0919](https://intranet.hbtn.io/batches/27) 
        ([from 2021-04-15 to 2021-04-16](https://intranet.hbtn.io/batch_peer_learning_day_items/3105) 
)      [BOG-0919](https://intranet.hbtn.io/batches/26) 
        ([from 2021-04-15 to 2021-04-16](https://intranet.hbtn.io/batch_peer_learning_day_items/3104) 
)      [BOG-0619](https://intranet.hbtn.io/batches/23) 
        ([from 2021-01-07 to 2021-01-08](https://intranet.hbtn.io/batch_peer_learning_day_items/2413) 
)      [
        https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/
        60
](https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/) 
[
        https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/image
        46
](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/image) 
[
        https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/preprocessing/image
        44
](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/preprocessing/image) 
[
        http://ai.stanford.edu/blog/data-augmentation/
        41
](http://ai.stanford.edu/blog/data-augmentation/) 
[
        https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
        35
](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) 
[
        https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf
        7
](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) 
[
        https://fs.blog/2012/04/feynman-technique/
        1
](https://fs.blog/2012/04/feynman-technique/) 
[
        https://fs.blog/feynman-learning-technique/
        0
](https://fs.blog/feynman-learning-technique/) 
[
        https://fs.blog/2021/02/feynman-learning-technique/
        0
](https://fs.blog/2021/02/feynman-learning-technique/) 
All clear. Nothing to see here.##### Required projects
All clear. Nothing to see here.##### Dependent projects
All clear. Nothing to see here.## Resources
Read or watch :
* [Data Augmentation | How to use Deep Learning when you have Limited Data — Part 2](https://intranet.hbtn.io/rltoken/2jHe5oim91wZro4SRdoB1w) 

* [tf.image](https://intranet.hbtn.io/rltoken/SJyavhXgzGprWBKoU0p2Ow) 

* [tf.keras.preprocessing.image](https://intranet.hbtn.io/rltoken/gezEJPsqC-6-mGpI0B38Wg) 

* [Automating Data Augmentation: Practice, Theory and New Direction](https://intranet.hbtn.io/rltoken/wboFN7gUujerC1dfHX24PQ) 

## Learning Objectives
At the end of this project, you are expected to be able to  [explain to anyone](https://intranet.hbtn.io/rltoken/zOatgAKBN76XGs6z4iJ0rQ) 
 ,  without the help of Google :
### General
* What is data augmentation?
* When should you perform data augmentation?
* What are the benefits of using data augmentation?
* What are the various ways to perform data augmentation?
* How can you use ML to automate data augmentation?
## Requirements
### General
* Allowed editors:  ` vi ` ,  ` vim ` ,  ` emacs ` 
* All your files will be interpreted/compiled on Ubuntu 16.04 LTS using  ` python3 `  (version 3.6.12)
* Your files will be executed with  ` numpy `  (version 1.16) and  ` tensorflow `  (version 1.15)
* All your files should end with a new line
* The first line of all your files should be exactly  ` #!/usr/bin/env python3 ` 
* All of your files must be executable
* A  ` README.md `  file, at the root of the folder of the project, is mandatory
* Your code should follow the  ` pycodestyle `  style (version 2.4)
* All your modules should have documentation ( ` python3 -c 'print(__import__("my_module").__doc__)' ` )
* All your classes should have documentation ( ` python3 -c 'print(__import__("my_module").MyClass.__doc__)' ` )
* All your functions (inside and outside a class) should have documentation ( ` python3 -c 'print(__import__("my_module").my_function.__doc__)' `  and  ` python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)' ` )
* Unless otherwise stated, you cannot import any module except  ` import tensorflow as tf ` 
## Download TF Datasets
 ` pip install --user tensorflow-datasets
 ` ## Tasks
### 0. Flip
          Level: 0                    Manual review           Progress vs Score  Task Body Write a function   ` def flip_image(image): `   that flips an image horizontally:
*  ` image `  is a 3D  ` tf.Tensor `  containing the image to flip
* Returns the flipped image
```bash
$ cat 0-main.py
#!/usr/bin/env python3

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
flip_image = __import__('0-flip').flip_image

tf.compat.v1.enable_eager_execution()
tf.compat.v1.set_random_seed(0)

doggies = tfds.load('stanford_dogs', split='train', as_supervised=True)
for image, _ in doggies.shuffle(10).take(1):
    plt.imshow(flip_image(image))
    plt.show()
$ ./0-main.py

```
 ![](https://s3.eu-west-3.amazonaws.com/hbtn.intranet/uploads/medias/2020/10/3c70d4fb24140e583ec2cc640bba178f090c3829.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4MYA5JM5DUTZGMZG%2F20221223%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221223T134732Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=a9aec363889d3b424435f2244bd59847880a1cbc2e310ede16d7ea2256572997) 

 Task URLs  Github information Repo:
* GitHub repository:  ` holbertonschool-machine_learning ` 
* Directory:  ` pipeline/0x04-data_augmentation ` 
* File:  ` 0-flip.py ` 
* Code language:                 `  `  (project based)            
 Self-paced manual review  Panel footer - Controls 
### 1. Crop
          Level: 0                    Manual review           Progress vs Score  Task Body Write a function   ` def crop_image(image, size): `   that performs a random crop of an image:
*  ` image `  is a 3D  ` tf.Tensor `  containing the image to crop
*  ` size `  is a tuple containing the size of the crop
* Returns the cropped image
```bash
$ cat 1-main.py
#!/usr/bin/env python3

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
crop_image = __import__('1-crop').crop_image

tf.compat.v1.enable_eager_execution()
tf.compat.v1.set_random_seed(1)

doggies = tfds.load('stanford_dogs', split='train', as_supervised=True)
for image, _ in doggies.shuffle(10).take(1):
    plt.imshow(crop_image(image, (200, 200, 3)))
    plt.show()
$ ./1-main.py

```
 ![](https://s3.eu-west-3.amazonaws.com/hbtn.intranet/uploads/medias/2020/10/e3b06484b6d2c0dcdd99a447fb2e83e2975b758a.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4MYA5JM5DUTZGMZG%2F20221223%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221223T134732Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=5c237a1fbc091ea9b87dcedaf92cd2683092f92c724b5cb764c3cab78ce29d8c) 

 Task URLs  Github information Repo:
* GitHub repository:  ` holbertonschool-machine_learning ` 
* Directory:  ` pipeline/0x04-data_augmentation ` 
* File:  ` 1-crop.py ` 
* Code language:                 `  `  (project based)            
 Self-paced manual review  Panel footer - Controls 
### 2. Rotate
          Level: 0                    Manual review           Progress vs Score  Task Body Write a function   ` def rotate_image(image): `   that rotates an image by 90 degrees counter-clockwise:
*  ` image `  is a 3D  ` tf.Tensor `  containing the image to rotate
* Returns the rotated image
```bash
$ cat 2-main.py
#!/usr/bin/env python3

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
rotate_image = __import__('2-rotate').rotate_image

tf.compat.v1.enable_eager_execution()
tf.compat.v1.set_random_seed(2)

doggies = tfds.load('stanford_dogs', split='train', as_supervised=True)
for image, _ in doggies.shuffle(10).take(1):
    plt.imshow(rotate_image(image))
    plt.show()
$ ./2-main.py

```
 ![](https://s3.eu-west-3.amazonaws.com/hbtn.intranet/uploads/medias/2020/10/670106424f5b215f33b4c0f39699ae1ffe89dbb3.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4MYA5JM5DUTZGMZG%2F20221223%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221223T134732Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d901ac515017289812eb9e0efa2459c953add5865d7373af75b34de65cf90ab9) 

 Task URLs  Github information Repo:
* GitHub repository:  ` holbertonschool-machine_learning ` 
* Directory:  ` pipeline/0x04-data_augmentation ` 
* File:  ` 2-rotate.py ` 
* Code language:                 `  `  (project based)            
 Self-paced manual review  Panel footer - Controls 
### 3. Shear
          Level: 0                    Manual review           Progress vs Score  Task Body Write a function   ` def shear_image(image, intensity): `   that randomly shears an image:
*  ` image `  is a 3D  ` tf.Tensor `  containing the image to shear
*  ` intensity `  is the intensity with which the image should be sheared
* Returns the sheared image
```bash
$ cat 3-main.py
#!/usr/bin/env python3

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
shear_image = __import__('3-shear').shear_image

tf.compat.v1.enable_eager_execution()
tf.compat.v1.set_random_seed(3)

doggies = tfds.load('stanford_dogs', split='train', as_supervised=True)
for image, _ in doggies.shuffle(10).take(1):
    plt.imshow(shear_image(image, 50))
    plt.show()
$ ./3-main.py

```
 ![](https://s3.eu-west-3.amazonaws.com/hbtn.intranet/uploads/medias/2020/10/cd5148646829e2f9b540cea1833d34d5f89faf2c.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4MYA5JM5DUTZGMZG%2F20221223%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221223T134732Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0cc3049f74d7b7300fe85d61653bf981d564d25c572f83224f4b5e050e07683b) 

 Task URLs  Github information Repo:
* GitHub repository:  ` holbertonschool-machine_learning ` 
* Directory:  ` pipeline/0x04-data_augmentation ` 
* File:  ` 3-shear.py ` 
* Code language:                 `  `  (project based)            
 Self-paced manual review  Panel footer - Controls 
### 4. Brightness
          Level: 0                    Manual review           Progress vs Score  Task Body Write a function   ` def change_brightness(image, max_delta): `   that randomly changes the brightness of an image:
*  ` image `  is a 3D  ` tf.Tensor `  containing the image to change
*  ` max_delta `  is the maximum amount the image should be brightened (or darkened)
* Returns the altered image
```bash
$ cat 4-main.py
#!/usr/bin/env python3

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
change_brightness = __import__('4-brightness').change_brightness

tf.compat.v1.enable_eager_execution()
tf.compat.v1.set_random_seed(4)

doggies = tfds.load('stanford_dogs', split='train', as_supervised=True)
for image, _ in doggies.shuffle(10).take(1):
    plt.imshow(change_brightness(image, 0.3))
    plt.show()
$ ./4-main.py

```
 ![](https://s3.eu-west-3.amazonaws.com/hbtn.intranet/uploads/medias/2020/10/3001edca791b04ccde934a44fe3095b1e544a425.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4MYA5JM5DUTZGMZG%2F20221223%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221223T134732Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=641d5c8a4a5b2ab72ccdc50f04e3aff29584b327ff642966350fc4327ddd8f43) 

 Task URLs  Github information Repo:
* GitHub repository:  ` holbertonschool-machine_learning ` 
* Directory:  ` pipeline/0x04-data_augmentation ` 
* File:  ` 4-brightness.py ` 
* Code language:                 `  `  (project based)            
 Self-paced manual review  Panel footer - Controls 
### 5. Hue
          Level: 0                    Manual review           Progress vs Score  Task Body Write a function   ` def change_hue(image, delta): `   that changes the hue of an image:
*  ` image `  is a 3D  ` tf.Tensor `  containing the image to change
*  ` delta `  is the amount the hue should change
* Returns the altered image
```bash
$ cat 5-main.py
#!/usr/bin/env python3

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
change_hue = __import__('5-hue').change_hue

tf.compat.v1.enable_eager_execution()
tf.compat.v1.set_random_seed(5)

doggies = tfds.load('stanford_dogs', split='train', as_supervised=True)
for image, _ in doggies.shuffle(10).take(1):
    plt.imshow(change_hue(image, -0.5))
    plt.show()
$ ./5-main.py

```
 ![](https://s3.eu-west-3.amazonaws.com/hbtn.intranet/uploads/medias/2020/10/a1e9035f2000dbb5649032ac424d1ebe980e8a07.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4MYA5JM5DUTZGMZG%2F20221223%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221223T134732Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=d7ca771a3b36eb30c1cd78b22237f0c3d0338a33efc05d9b1a98eb446453cddf) 

 Task URLs  Github information Repo:
* GitHub repository:  ` holbertonschool-machine_learning ` 
* Directory:  ` pipeline/0x04-data_augmentation ` 
* File:  ` 5-hue.py ` 
* Code language:                 `  `  (project based)            
 Self-paced manual review  Panel footer - Controls 
### 6. Automation
          Level: 0                    Manual review           Progress vs Score  Task Body Write a blog post describing step by step how to perform automated data augmentation. Try to explain every step you know of, and give examples. A total beginner should understand what you have written.
* Have at least one picture, at the top of the blog post
* Publish your blog post on Medium or LinkedIn
* Share your blog post at least on LinkedIn
* Write professionally and intelligibly
* Please, remember that these blogs must be written in English to further your technical ability in a variety of settings
Remember, future employers will see your articles; take this seriously, and produce something that will be an asset to your future
When done, please add all urls below (blog post, LinkedIn post, etc.)
 Task URLs #### Add URLs here:
                Save               Github information  Self-paced manual review  Panel footer - Controls 
### 7. PCA Color Augmentation
          Level: 2                    Manual review           Progress vs Score  Task Body Write a function   ` def pca_color(image, alphas): `   that performs PCA color augmentation as described in the  [AlexNet](https://intranet.hbtn.io/rltoken/zEzc_8giX0XkuUTiQsnqXA) 
  paper:
*  ` image `  is a 3D  ` tf.Tensor `  containing the image to change
*  ` alphas `  a tuple of length 3 containing the amount that each channel should change
* Returns the augmented image
```bash
$ cat 100-main.py
#!/usr/bin/env python3

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np
pca_color = __import__('100-pca').pca_color

tf.compat.v1.enable_eager_execution()
tf.compat.v1.set_random_seed(100)
np.random.seed(100)
doggies = tfds.load('stanford_dogs', split='train', as_supervised=True)
for image, _ in doggies.shuffle(10).take(1):
    alphas = np.random.normal(0, 0.1, 3)
    plt.imshow(pca_color(image, alphas))
    plt.show()
$ ./100-main.py

```
 ![](https://s3.eu-west-3.amazonaws.com/hbtn.intranet/uploads/medias/2020/10/73ecbc2cf5ac920e1e022178c420eb7c7585c345.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4MYA5JM5DUTZGMZG%2F20221223%2Feu-west-3%2Fs3%2Faws4_request&X-Amz-Date=20221223T134732Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2f4e7806c77272289ef6b3ec9d73f86432dc5f809a037fec86759e83a6523432) 

 Task URLs  Github information Repo:
* GitHub repository:  ` holbertonschool-machine_learning ` 
* Directory:  ` pipeline/0x04-data_augmentation ` 
* File:  ` 100-pca.py ` 
* Code language:                 `  `  (project based)            
 Self-paced manual review  Panel footer - Controls 
Copyright © 2022 Holberton Inc, All rights reserved.